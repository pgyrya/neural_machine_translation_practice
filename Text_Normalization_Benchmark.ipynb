{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#import keras\n",
    "#from keras.preprocessing.text import text_to_word_sequence\n",
    "#from sklearn                  import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported  133744 records\n",
      "Selected 133540 records out of 133744 for modeling.\n",
      "Split selected records into  \n",
      " - training sample (66565 records),  \n",
      " - validation sample (33515 records) used to select best model candidates, \n",
      " - testing sample (33460 records) used to review model quality\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Step 1 - import data \n",
    "# Initially, subset to a small batch to see whether the process \n",
    "# I intend to implement works -e.g. working with example of numbers only\n",
    "###############################################################################\n",
    "folder = '~/projects/text_normalization/'\n",
    "df0 = pd.read_csv(folder + 'en_train_cardinals.csv', nrows = 1000000, dtype = {'sentence_id': np.int32,\n",
    "                                          'token_id'   : np.int32,\n",
    "                                          'class' : str,\n",
    "                                          'before': str,\n",
    "                                          'after' : str})\n",
    "\n",
    "#df0 = pd.concat(chunk for chunk in csv_chunks)\n",
    "total_number_of_input_phrases           = df0.shape[0]\n",
    "print('Imported ', total_number_of_input_phrases, 'records')\n",
    "\n",
    "#review imported dataset\n",
    "#print(df0.loc[9:28,['class', 'before','after']])\n",
    "#print(df0.loc[number_of_input_phrases-10:number_of_input_phrases-1,['class', 'before','after']])\n",
    "\n",
    "#Subset the original data frame to areas of interest for practice\n",
    "#df = df0[df0['class'] =='CARDINAL'].reset_index() #'DIGIT', 'DECIMAL')\n",
    "selected_types_set = {'CARDINAL'}\n",
    "#selected_types_set = {'DIGIT','CARDINAL','ORDINAL','DECIMAL', 'FRACTION', 'MONEY', 'MEASURE', 'DATE', 'TELEPHONE', 'TIME'} \n",
    "#not_selected_types_set = {'PLAIN', 'PUNCT'} #more to be added\n",
    "type_match = lambda type: type in selected_types_set\n",
    "#df = df0[df0['class'].apply(type_match)==True].reset_index(drop=True)\n",
    "\n",
    "df1 = df0[df0['class'].apply(type_match)==True].reset_index(drop=True)\n",
    "\n",
    "# Next, focus on cardinals written with at most 10 symbols\n",
    "df  = df1[df1['before'].apply(len)<=10].reset_index(drop=True)\n",
    "\n",
    "#print(df.loc[9:28,['class', 'before','after']])\n",
    "\n",
    "number_of_input_phrases              = df.shape[0]\n",
    "print('Selected %i records out of %i for modeling.'%(number_of_input_phrases,total_number_of_input_phrases))\n",
    "\n",
    "#df.head()\n",
    "#df.shape\n",
    "\n",
    "#Split input data into development, validation and testing data frames\n",
    "#np.random.seed(217)\n",
    "random.seed(217)\n",
    "df['r'] = [random.uniform(0,1) for _ in df.index]\n",
    "#print(df['r'])\n",
    "\n",
    "df_train= df[ df['r'] <  0.5                     ].reset_index(drop=True)\n",
    "df_val  = df[(df['r'] >= 0.5 ) & (df['r'] < 0.75)].reset_index(drop=True)\n",
    "df_test = df[ df['r'] >= 0.75                    ].reset_index(drop=True)\n",
    "\n",
    "\n",
    "data_size_train = df_train.shape[0]\n",
    "data_size_val   = df_val.shape[0]\n",
    "data_size_test  = df_test.shape[0]\n",
    "\n",
    "print('Split selected records into ',\n",
    "      '\\n - training sample (%i records), '%data_size_train,\n",
    "      '\\n - validation sample (%i records) used to select best model candidates,'%data_size_val,\n",
    "      '\\n - testing sample (%i records) used to review model quality'%data_size_test)\n",
    "\n",
    "#print(df['before'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 133540, 'hundred': 39692, 'one': 30677, 'two': 25793, 'three': 17628, 'thousand': 14851, 'four': 14320, 'five': 13968, 'twenty': 13922, 'six': 11044, 'seven': 10072, 'nine': 9961, 'eight': 9761, 'thirty': 9434, 'fifty': 8029, 'forty': 8015, 'sixty': 6602, 'seventy': 5955, 'eighty': 5696, 'ninety': 5342, 'ten': 3988, 'twelve': 2835, 'eleven': 2356, 'fifteen': 2296, 'thirteen': 2133, 'eighteen': 2049, 'fourteen': 2021, 'sixteen': 1847, 'nineteen': 1618, 'seventeen': 1576, 'minus': 867, 'zero': 783, 'million': 757, 'billion': 82, \"two's\": 3, \"four's\": 2, \"thirteen's\": 1, \"three's\": 1, \"seven's\": 1}\n",
      "Number of distinct input tokens used: 27\n",
      "0 symbols represented via default input token.\n",
      "Number of distinct output tokens used: 40\n",
      "0 symbols represented via default input token.\n",
      "Shape of the encoder input data is: (133540,10,27)\n",
      "Shape of the decoder target data is: (133540,10,40) \n",
      "Training and validation split are: (66565,33515)\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Step 2   - Transform imported data into vector form\n",
    "#      2.1 - Identify tokens that are part of the input and output vocabulary\n",
    "#      ...\n",
    "###############################################################################\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "DEFAULT_TOKEN = '[?]'\n",
    "\n",
    "str_to_list_input  = lambda s: list(str(s).lower())\n",
    "str_to_list_output = lambda s: str(s).lower().split()  + ['\\n']\n",
    "\n",
    "count_input_tokens = lambda s: len(str_to_list_input(s))\n",
    "count_output_tokens= lambda s: len(str_to_list_output(s))\n",
    "\n",
    "# test functionality\n",
    "str_to_list_input ('Test Test 1 2 3')\n",
    "str_to_list_output ('Test Test 1 2 3')\n",
    "\n",
    "#input_list_of_lists = df['before'].apply(str_to_list_input)\n",
    "#output_list_of_lists= df['after'].apply(str_to_list_output)\n",
    "# TODO - consider appending start and end tokens to beginning and the end\n",
    "\n",
    "input_symbols_counter = Counter([i for slist in df['before'].apply(str_to_list_input) \n",
    "                                 for i in slist])\n",
    "output_symbols_counter= Counter([i for slist in df['after'].apply(str_to_list_output) \n",
    "                                 for i in slist]) \n",
    "\n",
    "#len(input_symbols_counter)\n",
    "#len(output_symbols_counter)\n",
    "\n",
    "def top(input_dict, top_N = 200):\n",
    "    appearances_count = dict(sorted(\n",
    "            input_dict.items(), key=itemgetter(1), reverse = True))\n",
    "       \n",
    "    #tokenize first top_N items as separate items, the rest as single item\n",
    "    index = dict([(key, min(i,top_N)) for i, key in enumerate(appearances_count.keys())])\n",
    "    \n",
    "    #setup reverse lookup, with default symbol replacing non-common tokens\n",
    "    reverse_index = dict([(i, key) for key, i in index.items() if i<top_N])\n",
    "    reverse_index[top_N] = DEFAULT_TOKEN\n",
    "    \n",
    "    return index, reverse_index, appearances_count \n",
    "\n",
    "input_token_index, reverse_input_token_index, input_token_appearances = top(\n",
    "        input_symbols_counter, 100)\n",
    "\n",
    "output_token_index, reverse_output_token_index, output_token_appearances = top(\n",
    "        output_symbols_counter, 1000)\n",
    "\n",
    "print(output_token_appearances)\n",
    "#input_token_index\n",
    "#len(input_token_index)\n",
    "#input_token_appearances\n",
    "\n",
    "num_distinct_input_tokens  = len(reverse_input_token_index)\n",
    "num_distinct_output_tokens = len(reverse_output_token_index)\n",
    "\n",
    "print ('Number of distinct input tokens used:' , num_distinct_input_tokens )\n",
    "print ('%d symbols represented via default input token.' % (len(input_token_index) - num_distinct_input_tokens + 1) )\n",
    "\n",
    "print ('Number of distinct output tokens used:', num_distinct_output_tokens)\n",
    "print ('%d symbols represented via default input token.' % (len(output_token_index) - num_distinct_output_tokens + 1) )\n",
    "\n",
    "#print(input_token_appearances)\n",
    "\n",
    "###############################################################################\n",
    "# Step 2   - Transform imported data into vector form\n",
    "#      ...\n",
    "#      2.2 - Vectorize input via one-hot encoding into a Numpy array, preparing\n",
    "#            to feed input symbols from before column into seq-to-seq model\n",
    "#            Also vectorize output, prepating to feed translations as outputs\n",
    "###############################################################################\n",
    "\n",
    "max_tokens_per_input_sentence    = 10 #25 \n",
    "max_tokens_per_output_sentence   = 10 #25 #100\n",
    "\n",
    "# initialize encoder input data as generator of 2D NumPy array with dimensions:\n",
    "# 1) maximum sentence length for encoder\n",
    "# 2) number of encoder tokens (origin language)\n",
    "\n",
    "# initialize decoder input data as generator of 2D NumPy array with dimensions:\n",
    "# 1) maximum sentence length for decoder\n",
    "# 2) number of decoder tokens (destination language)\n",
    "\n",
    "input_shape = (max_tokens_per_input_sentence, num_distinct_input_tokens)\n",
    "output_shape= (max_tokens_per_output_sentence, num_distinct_output_tokens)\n",
    "\n",
    "\n",
    "#encoder_input_data = np.zeros(input_shape, dtype='bool')\n",
    "#decoder_target_data = np.zeros(output_shape, dtype='bool')\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "print('Shape of the encoder input data is: (%i,%i,%i)'   %(number_of_input_phrases, input_shape[0] ,input_shape[1] ))\n",
    "print('Shape of the decoder target data is: (%i,%i,%i) ' %(number_of_input_phrases, output_shape[0],output_shape[1]))\n",
    "print('Training and validation split are: (%i,%i)'       %(data_size_train,         data_size_val))\n",
    "\n",
    "# fill in encoder input  data representing characters via one-hot encoding\n",
    "const_one = lambda seq: 1\n",
    "def lookup_and_transform(\n",
    "        dataset, \n",
    "        index_range, \n",
    "        verbose = False, \n",
    "        weight_function = const_one #could use const_one or len, for example\n",
    "        ):\n",
    "    index_list = list(index_range)\n",
    "    number_of_samples    = len(index_range)    \n",
    "    encoder_input        = np.zeros((number_of_samples,) + input_shape  , dtype='float32')\n",
    "    decoder_target       = np.zeros((number_of_samples,) + output_shape , dtype='float32')\n",
    "    decoder_time_weights = np.zeros((number_of_samples, output_shape[0]), dtype='float32')   #zero weight for decoder would mean disregarding any mismatches for this time point\n",
    "    #print(encoder_input.shape)\n",
    "\n",
    "    input_sequences = dataset['before'][index_list].apply(str_to_list_input ).tolist()    \n",
    "    target_sequences= dataset['after' ][index_list].apply(str_to_list_output).tolist()\n",
    "    #print (dataset.head(10))\n",
    "    \n",
    "    if verbose==True:\n",
    "        for input_sequence, target_sequence in zip(input_sequences, target_sequences):\n",
    "            print('Input sequence :', input_sequence, \n",
    "                  '\\n Corresponding target sequence:', target_sequence)\n",
    "        \n",
    "    for sample in range(number_of_samples):\n",
    "        for t, input_token in enumerate(input_sequences[sample]):\n",
    "            #if verbose==True:\n",
    "            #    print ('Processing input token ', input_token,\n",
    "            #           'with index ', input_token_index[input_token])\n",
    "            if t < max_tokens_per_input_sentence: \n",
    "                encoder_input[sample,t, input_token_index[input_token]] = 1.\n",
    "                \n",
    "        for t, output_token in enumerate(target_sequences[sample]):\n",
    "            #if verbose==True:\n",
    "            #    print ('Processing output token ', output_token,\n",
    "            #           'with index ', output_token_index[output_token])\n",
    "            if t < max_tokens_per_output_sentence:\n",
    "                decoder_target[sample,t, output_token_index[output_token]] = 1. \n",
    "                decoder_time_weights[sample, t] = weight_function(target_sequences[sample]) #previously set to 1\n",
    "                if (output_token.lower() == 'nan'):  # Write warning message\n",
    "                    print('Warning: NaN output token detected in subsample, row #', sample, \n",
    "                          'In the sentence:', ' '.join(target_sequences[sample]),\n",
    "                          'Index range requested: (%i,%i)'% (index_range[0], index_range[-1]))\n",
    "            \n",
    "    return encoder_input, decoder_target, decoder_time_weights\n",
    "\n",
    "#encoder_input, decoder_target, decoder_time_weights = lookup_and_transform(df_train,range(0,1), True)\n",
    "#encoder_input.sum()\n",
    "#encoder_input\n",
    "#lookup_and_transform(df_train,range(0,64), True)\n",
    "#lookup_and_transform(df_train,range(0,64), True)[0].shape\n",
    "    \n",
    "#lookup_and_transform(df_train,range(0,64))\n",
    "#list([1,2,3])\n",
    "#list(range(1,3+1))\n",
    "#print(df_train.loc[9])\n",
    "#print (reverse_input_token_index)    \n",
    "#len(range(1,3+1))\n",
    "\n",
    "# These generators are expected to loop over data indefinitely, generating batches\n",
    "# of data for model development and validation    \n",
    "def training_data_generator(batch_size = 64, dataset = df_train, verbose = False):\n",
    "    batch_index = 0    \n",
    "    batches_fitting_in_train_data = int(dataset.shape[0]/ batch_size)\n",
    "    while True:        \n",
    "        #print ('Generating training data with index from %i to %i'%(batch_size *  batch_index,batch_size * (batch_index + 1)-1))\n",
    "        yield lookup_and_transform(dataset, \n",
    "                                   range(batch_size * batch_index, batch_size * (batch_index + 1)),\n",
    "                                   verbose)\n",
    "        batch_index += 1\n",
    "        if batch_index >= batches_fitting_in_train_data: batch_index = 0 #restart generator\n",
    "\n",
    "\n",
    "def validation_data_generator(batch_size = 64, dataset = df_val):\n",
    "    batch_index_val = 0    \n",
    "    batches_fitting_in_val_data = int(dataset.shape[0]/ batch_size)\n",
    "    while True: \n",
    "        #print ('Generating validation data with index from %i to %i'%(batch_size *  batch_index_val,batch_size * (batch_index_val + 1)-1))\n",
    "        yield lookup_and_transform(dataset, \n",
    "                                   range(batch_size *  batch_index_val, batch_size * (batch_index_val + 1)))\n",
    "        batch_index_val += 1\n",
    "        if batch_index_val >= batches_fitting_in_val_data: batch_index_val = 0 #restart generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npfkffcg3Pc3BsPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe58ba75860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpVxUjEzs8o4qZiZWWX+P5KaCsxOtGxOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe58a289198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Review dataset by input and output length\n",
    "###############################################################################\n",
    "df0['input_length']  = df0['before'].apply(count_input_tokens) \n",
    "df0['output_length'] = df0['after'].apply(count_output_tokens) \n",
    "input_appearances_by_length = df0['input_length'].value_counts().sort_index()\n",
    "output_appearances_by_length = df0['output_length'].value_counts().sort_index()\n",
    "input_appearences_by_length  =  input_appearances_by_length.sort_index()\n",
    "output_appearences_by_length = output_appearances_by_length.sort_index()\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(1)\n",
    "plt.bar(range(len(input_appearances_by_length)),input_appearances_by_length)\n",
    "plt.xticks(range(len(input_appearances_by_length)), input_appearances_by_length.index)\n",
    "plt.xlabel('Number of input tokens (symbols)')\n",
    "plt.ylabel('Appearances')\n",
    "#plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.bar(range(len(output_appearences_by_length)),output_appearences_by_length)\n",
    "plt.xticks(range(len(output_appearences_by_length)), output_appearences_by_length.index)\n",
    "plt.xlabel('Number of output tokens (words)')\n",
    "plt.ylabel('Appearances')\n",
    "#plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 10, 27)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "LSTM_encoder (LSTM)              [(None, 500), (None,  1056000     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Encoder_Final_States (Concatenat (None, 1000)          0           LSTM_encoder[0][1]               \n",
      "                                                                   LSTM_encoder[0][2]               \n",
      "____________________________________________________________________________________________________\n",
      "Dropout_1 (Dropout)              (None, 1000)          0           Encoder_Final_States[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "Repeat (RepeatVector)            (None, 10, 1000)      0           Dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "Decoder (LSTM)                   (None, 10, 500)       3002000     Repeat[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "Dropout_2 (Dropout)              (None, 10, 500)       0           Decoder[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 10, 40)        20040       Dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4,078,040\n",
      "Trainable params: 4,078,040\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models             import Sequential, Model\n",
    "from keras.layers             import Dense, Dropout, TimeDistributed, Bidirectional, Input\n",
    "from keras.layers             import Permute, Multiply, LSTM, Concatenate, Flatten\n",
    "from keras.layers.core        import RepeatVector\n",
    "from keras.callbacks          import ModelCheckpoint  \n",
    "\n",
    "# New version of the encoder-decoder model, with internal memory instead of attention mechanism\n",
    "\n",
    "encoder_units = 500\n",
    "decoder_units = 500 \n",
    "\n",
    "# TODO define input shape of vectorized sentences more precisely\n",
    "# Note in the example of integer inputs, the shape was defined as: (pad_length,)\n",
    "input_sentences_vectorized = Input(shape = input_shape, dtype='float32')\n",
    "\n",
    "# Encode input symbols into a vector representation of specified dimension\n",
    "# TODO may want to make encoder bi-directional\n",
    "rnn_encoded, encoder_final_state_hidden, encoder_final_state_cell = LSTM(\n",
    "        encoder_units, \n",
    "        return_sequences = False, \n",
    "        return_state     = True, \n",
    "        name             ='LSTM_encoder')(input_sentences_vectorized)\n",
    "\n",
    "#rnn_encoded = Bidirectional(LSTM(encoder_units, return_sequences = True),\n",
    "#                            name      ='bidirectional_LSTM_encoder',\n",
    "#                            merge_mode='concat')(input_sentences_vectorized)\n",
    "\n",
    "# Repeat encoded state vector so that decoder has access to it during each decoding step\n",
    "# TODO ensure we pick the most relevant state of the encoder\n",
    "encoder_final_states = keras.layers.Concatenate(axis=-1, name = 'Encoder_Final_States')([encoder_final_state_hidden, encoder_final_state_cell])\n",
    "dropout_1 = Dropout(0.05, name = 'Dropout_1')(encoder_final_states)\n",
    "encoded_repeated = RepeatVector(max_tokens_per_output_sentence, name = 'Repeat')(dropout_1)\n",
    "\n",
    "decoder_vectors  = LSTM(\n",
    "        decoder_units, \n",
    "        return_sequences=True, \n",
    "#        initial_state=[encoder_final_state_hidden, encoder_final_state_cell],\n",
    "        name = 'Decoder')(encoded_repeated)\n",
    "\n",
    "dropout_2 = Dropout(0.05, name = 'Dropout_2')(decoder_vectors)\n",
    "\n",
    "output_token_probabilities = TimeDistributed(Dense(\n",
    "        num_distinct_output_tokens, \n",
    "        activation = 'softmax', \n",
    "        name = 'Probabilities'))(dropout_2)\n",
    "\n",
    "model = Model(input_sentences_vectorized, output_token_probabilities )\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Prepare model optimization routine and fit the model\n",
    "###############################################################################\n",
    "np.random.seed(1234)\n",
    "\n",
    "#default_sgd_optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Consider using keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        if hasattr(self, 'loss') ==False:\n",
    "            self.loss         = []\n",
    "            self.val_loss     = []\n",
    "            self.accuracy     = []\n",
    "            self.val_accuracy = []\n",
    "           #self.lr       = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.accuracy.append(logs.get('weighted_acc'))\n",
    "        self.val_accuracy.append(logs.get('val_weighted_acc'))\n",
    "       #self.lr.append(step_decay(len(self.losses)))\n",
    "\n",
    "global_loss_history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Prepare model optimization routine and fit the model\n",
    "###############################################################################\n",
    "np.random.seed(1234)\n",
    "\n",
    "#default_sgd_optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Consider using keras.callbacks.LearningRateScheduler(schedule)\n",
    "       \n",
    "#model.load_weights('saved_models/best.hdf5', by_name=False)\n",
    "def compile_and_fit_the_model(\n",
    "        initial_epoch    = 0,\n",
    "        epochs           = 10,\n",
    "        batch_size       = 64,\n",
    "        verbose          = True,\n",
    "        new_optimizer    = None,\n",
    "        load_weights     = False,\n",
    "        file_label       = 'best',\n",
    "        filter_categories= {'CARDINAL'}\n",
    "        ):\n",
    "    \n",
    "    df_train_subset = df_train\n",
    "    df_val_subset   = df_val\n",
    "    \n",
    "    if len(filter_categories)>0:\n",
    "        # TODO: Subset original data to provided filter, then re-index\n",
    "        # This may allow the model to learn from simpler (smaller) datasets first\n",
    "        type_match_new  = lambda type: type in filter_categories\n",
    "        df_train_subset = df_train[df_train['class'].apply(type_match_new)==True].reset_index(drop=True)\n",
    "        \n",
    "        df_val_subset   = df_val[df_val['class'].apply(type_match_new)==True].reset_index(drop=True)\n",
    "\n",
    "    subset_data_size_train = df_train_subset.shape[0]\n",
    "    subset_data_size_val   = df_val_subset.shape[0]\n",
    "    \n",
    "    print ('Training on %i observations '%subset_data_size_train,\n",
    "           '\\nValidating on %i observations'%subset_data_size_val)\n",
    "    \n",
    "    #print(df_train_subset[-25:-1])\n",
    "    #save_data_frame_to_Excel(df_train_subset[0:65530],'df_train_subset.xls')\n",
    "\n",
    "    if new_optimizer: #compile optimization if new optimizer is provided\n",
    "        model.compile(\n",
    "            loss              = 'categorical_crossentropy', # reward ranking observed translations as likely\n",
    "            optimizer         = new_optimizer, \n",
    "            sample_weight_mode= 'temporal',\n",
    "            weighted_metrics  = ['accuracy'])    \n",
    "    \n",
    "    filename      = 'saved_models/' + file_label + '_epochs' + str(initial_epoch+1) +'_' + str(epochs) + '.hdf5'\n",
    "    checkpointer1 = ModelCheckpoint(\n",
    "            save_best_only= True,\n",
    "            verbose       = 1, \n",
    "            filepath      = filename)\n",
    "    if load_weights==True:\n",
    "        print('Loading model weights...')\n",
    "        model.load_weights(filename, by_name=False)    \n",
    "        print('Done')\n",
    "   \n",
    "    model.fit_generator(\n",
    "            generator           = training_data_generator(batch_size, df_train_subset, False), #input/output arrays\n",
    "            validation_data     = validation_data_generator(batch_size, df_val_subset),\n",
    "            epochs              = epochs,\n",
    "            callbacks           = [checkpointer1, global_loss_history], \n",
    "            verbose             = verbose,\n",
    "            steps_per_epoch     = int(subset_data_size_train/ batch_size),\n",
    "            shuffle             = False,\n",
    "            max_queue_size      = 64,\n",
    "            validation_steps    = int(subset_data_size_val  / batch_size),\n",
    "            initial_epoch       = initial_epoch\n",
    "            )\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 66977 observations  \n",
      "Validating on 33185 observations\n",
      "Epoch 1/1\n",
      "4185/4186 [============================>.] - ETA: 2s - loss: 0.6060 - weighted_acc: 0.8192Epoch 00000: val_loss improved from inf to 0.28264, saving model to saved_models/best_epochs1_1.hdf5\n",
      "4186/4186 [==============================] - 12007s - loss: 0.6059 - weighted_acc: 0.8192 - val_loss: 0.2826 - val_weighted_acc: 0.9132\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_the_model(epochs        = 1, \n",
    "                          initial_epoch = 0, \n",
    "                          batch_size    = 16, \n",
    "                          new_optimizer = 'rmsprop') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 66581 observations  \n",
      "Validating on 33333 observations\n",
      "Epoch 2/10\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.1755 - weighted_acc: 0.9474Epoch 00001: val_loss improved from inf to 0.12719, saving model to saved_models/best_epochs2_10.hdf5\n",
      "260/260 [==============================] - 1340s - loss: 0.1754 - weighted_acc: 0.9474 - val_loss: 0.1272 - val_weighted_acc: 0.9604\n",
      "Epoch 3/10\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.1234 - weighted_acc: 0.9625Epoch 00002: val_loss improved from 0.12719 to 0.09087, saving model to saved_models/best_epochs2_10.hdf5\n",
      "260/260 [==============================] - 1339s - loss: 0.1234 - weighted_acc: 0.9625 - val_loss: 0.0909 - val_weighted_acc: 0.9719\n",
      "Epoch 4/10\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.0975 - weighted_acc: 0.9705Epoch 00003: val_loss improved from 0.09087 to 0.08513, saving model to saved_models/best_epochs2_10.hdf5\n",
      "260/260 [==============================] - 1338s - loss: 0.0975 - weighted_acc: 0.9705 - val_loss: 0.0851 - val_weighted_acc: 0.9730\n",
      "Epoch 5/10\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.0794 - weighted_acc: 0.9754Epoch 00004: val_loss improved from 0.08513 to 0.06781, saving model to saved_models/best_epochs2_10.hdf5\n",
      "260/260 [==============================] - 1338s - loss: 0.0794 - weighted_acc: 0.9754 - val_loss: 0.0678 - val_weighted_acc: 0.9784\n",
      "Epoch 6/10\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.0660 - weighted_acc: 0.9797Epoch 00005: val_loss did not improve\n",
      "260/260 [==============================] - 1338s - loss: 0.0660 - weighted_acc: 0.9797 - val_loss: 0.0758 - val_weighted_acc: 0.9771\n",
      "Epoch 7/10\n",
      "259/260 [============================>.] - ETA: 28s - loss: 0.0595 - weighted_acc: 0.9821Epoch 00006: val_loss improved from 0.06781 to 0.05788, saving model to saved_models/best_epochs2_10.hdf5\n",
      "260/260 [==============================] - 9418s - loss: 0.0594 - weighted_acc: 0.9821 - val_loss: 0.0579 - val_weighted_acc: 0.9820\n",
      "Epoch 8/10\n",
      "259/260 [============================>.] - ETA: 46s - loss: 0.0476 - weighted_acc: 0.9853Epoch 00007: val_loss did not improve\n",
      "260/260 [==============================] - 14189s - loss: 0.0476 - weighted_acc: 0.9853 - val_loss: 0.0634 - val_weighted_acc: 0.9797\n",
      "Epoch 9/10\n",
      "259/260 [============================>.] - ETA: 46s - loss: 0.0418 - weighted_acc: 0.9871Epoch 00008: val_loss did not improve\n",
      "260/260 [==============================] - 14187s - loss: 0.0418 - weighted_acc: 0.9871 - val_loss: 0.0619 - val_weighted_acc: 0.9816\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d63f77727ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           \u001b[0mbatch_size\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                           new_optimizer = RMSprop(lr=0.001, decay = 0.0001)) \n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d31ba2e666fe>\u001b[0m in \u001b[0;36mcompile_and_fit_the_model\u001b[0;34m(initial_epoch, epochs, batch_size, verbose, new_optimizer, load_weights, file_label, filter_categories)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mmax_queue_size\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mvalidation_steps\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data_size_val\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0minitial_epoch\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             )\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue calibration with larger batch size and include learning rate\n",
    "model.load_weights('saved_models/best_epochs1_1.hdf5')\n",
    "compile_and_fit_the_model(epochs        = 10 , \n",
    "                          initial_epoch = 1  , \n",
    "                          batch_size    = 256, \n",
    "                          new_optimizer = RMSprop(lr=0.001, decay = 0.0001)) \n",
    "# Note default optimizers settings below:\n",
    "# keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 66581 observations  \n",
      "Validating on 33333 observations\n",
      "Epoch 10/20\n",
      "259/260 [============================>.] - ETA: 46s - loss: 0.0311 - weighted_acc: 0.9912Epoch 00009: val_loss improved from inf to 0.04449, saving model to saved_models/best_epochs10_20.hdf5\n",
      "260/260 [==============================] - 14246s - loss: 0.0312 - weighted_acc: 0.9912 - val_loss: 0.0445 - val_weighted_acc: 0.9863\n",
      "Epoch 11/20\n"
     ]
    }
   ],
   "source": [
    "#load best weights from previous calibration (note previously dropout layers were not used)\n",
    "model.load_weights('saved_models/best_epochs2_10.hdf5', by_name = False)\n",
    "\n",
    "#calibrate the model with smaller learning rate and keep decreasing it to ensure we make steps \n",
    "#right along the direction of a (stochastic) gradient\n",
    "compile_and_fit_the_model(epochs        = 10 , \n",
    "                          initial_epoch = 9 , \n",
    "                          batch_size    = 256, \n",
    "                          new_optimizer = RMSprop(lr=0.0002, decay = 0.00001)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 66595 observations  \n",
      "Validating on 33513 observations\n",
      "Epoch 11/15\n",
      "259/260 [============================>.] - ETA: 34s - loss: 0.0366 - weighted_acc: 0.9890Epoch 00010: val_loss improved from inf to 0.03307, saving model to saved_models/best_epochs11_15.hdf5\n",
      "260/260 [==============================] - 9220s - loss: 0.0365 - weighted_acc: 0.9890 - val_loss: 0.0331 - val_weighted_acc: 0.9900\n",
      "Epoch 12/15\n",
      "259/260 [============================>.] - ETA: 19s - loss: 0.0302 - weighted_acc: 0.9912Epoch 00011: val_loss improved from 0.03307 to 0.03233, saving model to saved_models/best_epochs11_15.hdf5\n",
      "260/260 [==============================] - 5226s - loss: 0.0302 - weighted_acc: 0.9912 - val_loss: 0.0323 - val_weighted_acc: 0.9904\n",
      "Epoch 13/15\n",
      "  9/260 [>.............................] - ETA: 1104s - loss: 0.0347 - weighted_acc: 0.9901"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-767f328d3e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                           \u001b[0minitial_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           \u001b[0mbatch_size\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                           new_optimizer = RMSprop(lr=0.0002, decay = 0.00001)) \n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-d31ba2e666fe>\u001b[0m in \u001b[0;36mcompile_and_fit_the_model\u001b[0;34m(initial_epoch, epochs, batch_size, verbose, new_optimizer, load_weights, file_label, filter_categories)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mmax_queue_size\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mvalidation_steps\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_data_size_val\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0minitial_epoch\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             )\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load best weights from previous calibration (note previously dropout layers were not used)\n",
    "model.load_weights('saved_models/best_epochs10_10.hdf5', by_name = False)\n",
    "\n",
    "#calibrate the model with smaller learning rate and keep decreasing it to ensure we make steps \n",
    "#right along the direction of a (stochastic) gradient\n",
    "compile_and_fit_the_model(epochs        = 12 , \n",
    "                          initial_epoch = 10 , \n",
    "                          batch_size    = 256, \n",
    "                          new_optimizer = RMSprop(lr=0.0002, decay = 0.00001)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 66565 observations  \n",
      "Validating on 33515 observations\n",
      "Epoch 13/15\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.0303 - weighted_acc: 0.9910Epoch 00012: val_loss improved from inf to 0.02929, saving model to saved_models/best_epochs13_15.hdf5\n",
      "260/260 [==============================] - 1335s - loss: 0.0303 - weighted_acc: 0.9910 - val_loss: 0.0293 - val_weighted_acc: 0.9914\n",
      "Epoch 14/15\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.0257 - weighted_acc: 0.9927Epoch 00013: val_loss did not improve\n",
      "260/260 [==============================] - 1338s - loss: 0.0257 - weighted_acc: 0.9927 - val_loss: 0.0301 - val_weighted_acc: 0.9909\n",
      "Epoch 15/15\n",
      "259/260 [============================>.] - ETA: 4s - loss: 0.0223 - weighted_acc: 0.9940Epoch 00014: val_loss improved from 0.02929 to 0.02895, saving model to saved_models/best_epochs13_15.hdf5\n",
      "260/260 [==============================] - 1341s - loss: 0.0224 - weighted_acc: 0.9940 - val_loss: 0.0290 - val_weighted_acc: 0.9914\n"
     ]
    }
   ],
   "source": [
    "#load best weights from previous calibration (note previously dropout layers were not used)\n",
    "model.load_weights('saved_models/best_epochs11_12.hdf5', by_name = False)\n",
    "\n",
    "#calibrate the model with smaller learning rate and keep decreasing it to ensure we make steps \n",
    "#right along the direction of a (stochastic) gradient\n",
    "compile_and_fit_the_model(epochs        = 15 , \n",
    "                          initial_epoch = 12 , \n",
    "                          batch_size    = 256, \n",
    "                          new_optimizer = RMSprop(lr=0.0002, decay = 0.00001)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 66565 observations  \n",
      "Validating on 33515 observations\n",
      "Epoch 17/20\n",
      "206/260 [======================>.......] - ETA: 239s - loss: 0.0189 - weighted_acc: 0.9951"
     ]
    }
   ],
   "source": [
    "#load best weights from previous calibration (note previously dropout layers were not used)\n",
    "#model.load_weights('saved_models/best_epochs13_15.hdf5', by_name = False)\n",
    "model.load_weights('saved_models/best_epochs16_16.hdf5', by_name = False)\n",
    "\n",
    "#calibrate the model with smaller learning rate and keep decreasing it to ensure we make steps \n",
    "#right along the direction of a (stochastic) gradient\n",
    "#compile_and_fit_the_model(epochs        = 16 , \n",
    "#                          initial_epoch = 15 , \n",
    "#                          batch_size    = 256, \n",
    "#                          new_optimizer = RMSprop(lr=0.0002, decay = 0.00001)) \n",
    "\n",
    "compile_and_fit_the_model(epochs        = 20 , \n",
    "                          initial_epoch = 16 , \n",
    "                          batch_size    = 256, \n",
    "                          new_optimizer = RMSprop(lr=0.0002, decay = 0.00001)) \n",
    "\n",
    "compile_and_fit_the_model(epochs        = 50 , \n",
    "                          initial_epoch = 20 , \n",
    "                          batch_size    = 256,\n",
    "                          new_optimizer = RMSprop(lr=0.00002, decay = 0.000001)\n",
    "                         ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Inference mode (sampling).\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "#    and a \"start of sequence\" token as target.\n",
    "#    Output will be the next target token\n",
    "# 3) Append the target token and repeat\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def sort_and_plot(array_of_values = None, lookup_labels = None, top_N = 3):\n",
    "    #plot 10 highest value elements in the dictionary\n",
    "    \n",
    "    dict1 = dict([(label, value)  for value, label in zip(array_of_values, lookup_labels)])\n",
    "    #print(dict1)\n",
    "    dict2 = dict(sorted(dict1.items(), key=itemgetter(1), reverse = True)[0:top_N])\n",
    "    #print(dict2)\n",
    "    elements_to_plot = min(top_N, len(dict2))\n",
    "    ind = np.arange(elements_to_plot,0,-1)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.barh(ind, list(dict2.values()))\n",
    "    plt.yticks(ind, list(dict2.keys()))\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "#sort_and_plot([0.1, 0.5, 0.4], ['a','b','c'])\n",
    "\n",
    "def decode_sequence(input_seq = None, graph_likely = True):\n",
    "    # Encode the input as state vectors.\n",
    "    #states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence for storing translated phrase\n",
    "    target_seq = np.zeros((1, 1, num_distinct_output_tokens))\n",
    "    \n",
    "    # May want to later populate the first character of target sequence with the start character.\n",
    "    #target_seq[0, 0, output_token_index['\\t']] = 1.\n",
    "\n",
    "    #print('Shape of model predictions is:', model.predict(input_seq).shape)\n",
    "    output_tokens_scores = model.predict(input_seq)[0,:,:]\n",
    "    #attention_flow       = attention_model.predict(input_seq)[0,:,:]\n",
    "    #print(output_tokens_scores.shape)\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    number_of_words_in_translated_sentence = 0 \n",
    "\n",
    "    #print(output_tokens_scores)\n",
    "\n",
    "    while not stop_condition:\n",
    "        # generate probability scores for each of the output tokens\n",
    "        # based on decoder model applied to encoded state and target sequence\n",
    "        #output_token_scores = decoder_model.predict([target_seq] + states_value)\n",
    "        output_token_scores = output_tokens_scores[number_of_words_in_translated_sentence,:]\n",
    "        \n",
    "        #print('Probability scores for this token sum up to %i%%'%int(100*output_token_scores.sum()))\n",
    "        \n",
    "        #print('Next token scores', output_token_scores) \n",
    "        \n",
    "        # Sample a token that has largest probability to appear next\n",
    "        #sampled_token_index = np.argmax(output_token_scores[0, -1, :])\n",
    "        sampled_token_index = np.argmax(output_token_scores)\n",
    "        if graph_likely==True: sort_and_plot(output_token_scores, output_token_index)\n",
    "        sampled_word = reverse_output_token_index[sampled_token_index]\n",
    "\n",
    "        if number_of_words_in_translated_sentence > 0: decoded_sentence += ' '\n",
    "            \n",
    "        decoded_sentence += sampled_word        \n",
    "        number_of_words_in_translated_sentence += 1\n",
    "        \n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_word == '\\n' or\n",
    "           number_of_words_in_translated_sentence >= max_tokens_per_output_sentence):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Add the sampled word to the sequence\n",
    "        word_vector = np.zeros((1, 1, num_distinct_output_tokens))\n",
    "        word_vector[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "#        print ('Best guess token: ', sampled_word, \n",
    "#               ' with associated score ', np.max(output_token_scores))\n",
    "\n",
    "        target_seq = np.concatenate([target_seq, word_vector], axis=1)\n",
    "                \n",
    "    #print ('target sequence: ',target_seq)\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Prepare functionality to translate input sentence\n",
    "#   1) vectorize sentence using one-hot encoding for each input symbol\n",
    "#   2) feed vectorized sentence into the model\n",
    "#   3) run step-by-step translation by picking most likely token at each step\n",
    "###############################################################################\n",
    "def vectorize(sentence):\n",
    "    # initialize decoder input data as 3D NumPy array of zeroes with dimensions:\n",
    "    # 1) 1\n",
    "    # 2) maximum sentence length for decoder\n",
    "    # 3) number of decoder tokens (destination language)\n",
    "    vectorized_sentence = np.zeros(\n",
    "        (1, max_tokens_per_input_sentence, num_distinct_input_tokens),\n",
    "        dtype='bool')\n",
    "    \n",
    "    # fill in encoder input  data representing characters via one-hot encoding\n",
    "    for t, char in enumerate(sentence):\n",
    "        if t < max_tokens_per_input_sentence:\n",
    "            vectorized_sentence[0, t, input_token_index[char]] = 1.\n",
    "       \n",
    "    #print('Vectorized sentence has %i tokens'%vectorized_sentence.sum())\n",
    "    return vectorized_sentence\n",
    "\n",
    "def translate(sentence = None, graph_likely = False):\n",
    "    #vectorized_sentence = vectorize('\\t' + sentence) \n",
    "    vectorized_sentence = vectorize(sentence.lower()) \n",
    "    #print('Number of symbols in vectorized sentence is %i: '%vectorized_sentence.sum())\n",
    "    decoded = decode_sequence(vectorized_sentence, graph_likely)\n",
    "    if decoded[-2:] == ' \\n': decoded = decoded[0:-2] #omit end token\n",
    "    #print (decoded)\n",
    "    return decoded   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD746Y1LGZwaNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe56c908f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe58a5942b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe56c8775c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe56bfba780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAC8ZJREFUeJzt3H+sZPVZx/HPA0v5UejWdDFBaLma\nLIkEiLSrwRhbTAkhYCCxqG1sFKxFMfYPtRqSJlrFKNRfSdWISyW1Wi2tMUpEpWkL0miBLtIuPxIK\ntkuFkrS1ulGJVNavf8yg1+2yd3j2zszu7OuVkJyZOcw855t77/ueM3O3xhgBgI5jlj0AAEcuEQGg\nTUQAaBMRANpEBIA2EQGgTUQAaBMRANpEBIC2LcseYN62bds21tbWlj0GwBHl/vvv//IY49SN9lv5\niKytrWXXrl3LHgPgiFJVT8yyn8tZALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0Lbyf2z44FN7\ns3bd7cseA2Ch9txw2UJex5kIAG0iAkCbiADQJiIAtIkIAG0iAkCbiADQJiIAtIkIAG0iAkCbiADQ\nJiIAtIkIAG0iAkCbiADQJiIAtIkIAG0iAkCbiADQJiIAtIkIAG0iAkCbiADQJiIAtIkIAG0iAkCb\niADQtpIRqaprqmpXVe3a98zeZY8DsLJWMiJjjJ1jjB1jjB3HnrR12eMArKyVjAgAiyEiALSJCABt\nIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJ\nCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJCABtW5Y9wLyde/rW7LrhsmWPAbCSnIkA0CYi\nALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0LbyEXnwqb1Zu+72ZY8B\nsJJWPiIAzI+IANAmIgC0iQgAbSICQJuIANAmIgC0iQgAbSICQJuIANAmIgC0iQgAbSICQJuIANAm\nIgC0iQgAbSICQJuIANAmIgC0iQgAbSICQJuIANAmIgC0HRERqar3VNXZy54DgP9vy7IHmMUY40eW\nPQMAX+uwOxOpqpdW1e1V9emqeqiqvr+q7qqqHVV1ZlU9VlXbquqYqvp4VV287JkBjlaH45nIJUm+\nMMa4LEmqamuSa5NkjPFEVd2Y5KYk9yZ5ZIzx4aVNCnCUO+zORJI8mOSiqrqxqr5zjLF3/YNjjPck\nOSXJjyV5+4GeoKquqapdVbVr3zN7D7QLAJvgsIvIGOMzSV6TSUx+pap+bv3jVXVSkjOmN09+gefY\nOcbYMcbYcexJW+c6L8DR7LC7nFVV35DkK2OMP6qqf09y1X673Jjk/UmeSHJzku9e7IQAPO+wOxNJ\ncm6S+6rqU0nekeSXnn+gql6X5FuT3DjGeH+Sr1bV1csZE4DD7kxkjHFHkjv2u/vCddsXrNv3exYx\nEwAHdjieiQBwhBARANpEBIA2EQGgTUQAaBMRANpEBIA2EQGgTUQAaBMRANpEBIA2EQGgTUQAaBMR\nANpEBIA2EQGgTUQAaBMRANpEBIA2EQGgTUQAaBMRANpEBIC2lY/IuadvzZ4bLlv2GAAraeUjAsD8\niAgAbSICQJuIANAmIgC0iQgAbSICQJuIANAmIgC0iQgAbSICQJuIANAmIgC0rXxEHnxq77JHAFhZ\nKx8RAOZHRABoExEA2kQEgDYRAaBNRABoExEA2kQEgDYRAaBNRABoExEA2kQEgDYRAaBNRABoExEA\n2kQEgDYRAaBNRABoExEA2kQEgDYRAaBNRABoExEA2kQEgLYNI1JVa1X10Ga/cFVdVVW/fYjPcVdV\n7dismQB4cQ67M5Gq2rLsGQCYzawRObaqbq6qh6vqw1V14vqzgKraVlV7pttXVdWfVdXfVNVjVfWu\n55+kqq6uqs9U1d8m+Y5197+3qn6jqu5McmNVvbSqbqmqT1bVA1V1xXS/E6vqA1W1u6puTXLiJq0D\nAA2z/ta/PcmbxhhvraoPJnnDBvt/S5Lzkzyb5NGq+q0kzyX5hSSvSbI3yZ1JHlj3/5yV5KIxxr6q\n+uUkHxtj/HBVvTzJfVX1kSQ/muSZMcZ5VXVekn+YcX4A5mDWiHxujPGp6fb9SdY22P+jY4y9SVJV\njyQ5M8m2JHeNMb40vf/WTMLxvA+NMfZNty9OcnlVvX16+4Qkr0ry2iTvTpIxxu6q2n2gF6+qa5Jc\nkyTHvuzUGQ8RgBdr1og8u257XyaXkZ7L/10OO2GD/Z9/nXGQ1/iPdduV5A1jjEfX71BVGz3H5EXG\n2JlkZ5Icf9r2DfcHoOdQ3ljfk8mlqSS5cob9701yYVW9oqqOS/K9B9n3jiRvq2k1qur86f13J/mB\n6X3nJDmvMTcAm+RQIvJrSa6tqr/P5FLVQY0xnk7yziSfSPKRHPz9jOuTHJdk9/TjxddP7//dJCdP\nL2P9bJL72tMDcMhqjNW+2nP8advHs08/tuwxAI4oVXX/GGPDv8M77P5OBIAjh4gA0CYiALSJCABt\nIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJCABtIgJAm4gA0CYiALSJ\nCABtIgJAm4gA0CYiALStfETOPX3rskcAWFkrHxEA5kdEAGgTEQDaRASANhEBoE1EAGgTEQDaRASA\nNhEBoK3GGMueYa6q6t+SPLrsOZZsW5IvL3uIJXL8R/fxJ9agc/xnjjFO3WinLb15jiiPjjF2LHuI\nZaqqXUfzGjj+o/v4E2swz+N3OQuANhEBoO1oiMjOZQ9wGDja18Dxc7SvwdyOf+XfWAdgfo6GMxEA\n5mRlIlJVl1TVo1X1eFVdd4DHj6+qW6eP31tVa4ufcn5mOP6fqqpHqmp3VX20qs5cxpzztNEarNvv\nyqoaVbVSn9aZ5fir6vumXwcPV9UfL3rGeZvh++BVVXVnVT0w/V64dBlzzkNV3VJVX6yqh17g8aqq\nd0/XZndVvXpTXniMccT/l+TYJP+Y5JuSvCTJp5Ocvd8+P57kpun2G5Pcuuy5F3z835XkpOn2tat0\n/LOuwXS/U5LcneSeJDuWPfeCvwa2J3kgyddNb3/9sudewhrsTHLtdPvsJHuWPfcmHv9rk7w6yUMv\n8PilSf46SSW5IMm9m/G6q3Im8m1JHh9jfHaM8dUkH0hyxX77XJHkD6bbf5rk9VVVC5xxnjY8/jHG\nnWOMZ6Y370lyxoJnnLdZvgaS5Pok70ryn4scbgFmOf63JvmdMca/JMkY44sLnnHeZlmDkeRl0+2t\nSb6wwPnmaoxxd5KvHGSXK5K8b0zck+TlVXXaob7uqkTk9CT/tO72k9P7DrjPGOO5JHuTvGIh083f\nLMe/3lsy+Y1klWy4BlV1fpJXjjH+cpGDLcgsXwNnJTmrqv6uqu6pqksWNt1izLIG70zy5qp6Mslf\nJXnbYkY7LLzYnxMzWZW/WD/QGcX+HzubZZ8j1czHVlVvTrIjyevmOtHiHXQNquqYJL+Z5KpFDbRg\ns3wNbMnkktaFmZyJfryqzhlj/OucZ1uUWdbgTUneO8b49ar69iR/OF2D/57/eEs3l5+Bq3Im8mSS\nV667fUa+9jT1f/epqi2ZnMoe7NTvSDLL8aeqLkryjiSXjzGeXdBsi7LRGpyS5Jwkd1XVnkyuCd+2\nQm+uz/o98BdjjP8aY3wuk39TbvuC5luEWdbgLUk+mCRjjE8kOSGTf1fqaDDTz4kXa1Ui8skk26vq\nG6vqJZm8cX7bfvvcluSHpttXJvnYmL7btAI2PP7ppZzfyyQgq3YtPNlgDcYYe8cY28YYa2OMtUze\nF7p8jLFrOeNuulm+B/48kw9YpKq2ZXJ567MLnXK+ZlmDzyd5fZJU1TdnEpEvLXTK5bktyQ9OP6V1\nQZK9Y4ynD/VJV+Jy1hjjuar6iSR3ZPIJjVvGGA9X1S8m2TXGuC3J72dy6vp4Jmcgb1zexJtrxuP/\n1SQnJ/nQ9PMEnx9jXL60oTfZjGuwsmY8/juSXFxVjyTZl+Rnxhj/vLypN9eMa/DTSW6uqp/M5FLO\nVavyy2RV/Ukmlyq3Td/z+fkkxyXJGOOmTN4DujTJ40meSXL1przuiqwfAEuwKpezAFgCEQGgTUQA\naBMRANpEBIA2EQGgTUQAaBMRANr+Bzf1rtyZoVk4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe56c7564e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'one hundred eighty six'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_weights('saved_models/best_epochs2_10.hdf5') # works well on -999,999\n",
    "#model.load_weights('saved_models/best_epochs10_10.hdf5') \n",
    "#model.load_weights('saved_models/best_epochs11_12.hdf5', by_name = False)\n",
    "model.load_weights('saved_models/best_epochs13_15.hdf5', by_name = False)\n",
    "#model.load_weights('saved_models/best_epochs16_16.hdf5', by_name = False)\n",
    "\n",
    "# Test translation mechanism\n",
    "#translate('911')\n",
    "#translate('X')\n",
    "#translate('1003', True)\n",
    "#translate('1')\n",
    "#translate('2')\n",
    "#translate('23', True)\n",
    "#translate('5')\n",
    "#translate('asdasda ')\n",
    "#translate('100', True)\n",
    "\n",
    "#translate('12', True)\n",
    "#translate('LXXXVIII', True)\n",
    "translate('CLXXXIII', True)\n",
    "\n",
    "#translate('-999,999')\n",
    "#translate('LXXXVIII')\n",
    "#translate('20151956')\n",
    "#translate('-742,791', True)\n",
    "\n",
    "#translate('-742,791', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(output_token_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Visualize model performance over time (weighted accuracy, loss)\n",
    "###############################################################################\n",
    "def plot_training_history(\n",
    "        data      = None, \n",
    "        x_axis_name = 'epoch',\n",
    "        y_axis_name = 'categorical cross-entropy loss',\n",
    "        y_limit_bottom = 0\n",
    "        ):\n",
    "    for metric_name, series in data.items():\n",
    "        plt.plot(range(len(series)), series, label = metric_name)\n",
    "    \n",
    "    plt.legend(loc=1)\n",
    "    plt.xlabel(x_axis_name)\n",
    "    plt.ylabel(y_axis_name)\n",
    "    if y_limit_bottom: plt.gca().set_ylim(bottom=0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_training_history({'training': global_loss_history.loss, 'validation':  global_loss_history.val_loss}) \n",
    "#plot_training_history( {'training': global_loss_history.accuracy, 'validation':  global_loss_history.val_accuracy},\n",
    "#                     y_axis_name = 'weighted accuracy', y_limit_bottom = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation accuracy: 0.986103\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Evaluate accuracy of translation on the modeling and testing data\n",
    "# Define function to evaluate accuracy on the dataset provided\n",
    "# 1) execute translation\n",
    "# 2) evaluate accuracy\n",
    "###############################################################################\n",
    "\n",
    "#model.load_weights('saved_models/best_epochs2_10.hdf5')\n",
    "#model.load_weights('saved_models/best_epochs13_15.hdf5')\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "def save_data_frame_to_Excel(dataset, save_data_to = 'saved.xls'):\n",
    "    writer = pd.ExcelWriter(save_data_to)\n",
    "    sheet_name = 'Sheet1'\n",
    "    dataset.to_excel(writer,sheet_name)\n",
    "    writer.save()\n",
    "    return\n",
    "\n",
    "translation_process = lambda sentence: translate(sentence)\n",
    "\n",
    "def translate_dataset(dataset = None, save_data_to = 'translated.xlsx', append = False):        \n",
    "    #print(dataset['before'])\n",
    "    dataset['translated']       = dataset['before'].apply(translation_process)\n",
    "    dataset['match']            = dataset['translated'] == dataset['after']\n",
    "    dataset['max_token_length'] = dataset['before'].apply(count_input_tokens)    \n",
    "    \n",
    "    number_of_phrases = dataset.shape[0]\n",
    "    number_of_phrases_correctly_tranlsated = dataset.loc[dataset['translated'] == dataset['after']].shape[0]\n",
    "    translation_accuracy = number_of_phrases_correctly_tranlsated / number_of_phrases \n",
    "    print('Translation accuracy: %4f'%translation_accuracy)\n",
    "    \n",
    "    #dataset.to_csv(save_data_to)\n",
    "    save_data_frame_to_Excel(dataset, save_data_to)\n",
    "    return\n",
    "\n",
    "translate_dataset(df_test, save_data_to = 'test_translated_Nov15_benchmark.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save global calibration history to file\n",
    "import pickle\n",
    "f = open('global_loss_history.file','wb')\n",
    "pickle.dump(global_loss_history, f )\n",
    "f.close()\n",
    "#global_loss_history = pickle.load('global_loss_history.file')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
